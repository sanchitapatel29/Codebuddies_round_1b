# Round 1B: Persona-Driven Document Intelligence

> Theme: â€œConnect What Matters â€” For the User Who Mattersâ€

This project is an offline, CPU-only **intelligent document analyst** that extracts and prioritizes the most relevant sections from a collection of PDFs â€” based on a specific **persona** and their **job-to-be-done**.

The pipeline is designed to handle various types of documents (e.g., research papers, financial reports, textbooks) and adapts to diverse personas and related goals.

---

## ğŸš€ Features

- âœ… **Offline & CPU-Only** (no internet required at runtime)
- ğŸ“„ **PDF Parsing & Chunking** using `PyMuPDF`
- ğŸ§  **Semantic Similarity Scoring** using `sentence-transformers`
- ğŸ§¾ **Structured Output** in the required `challenge1b_output.json` format
- âš¡ Fast & Lightweight (â‰¤ 1GB model, â‰¤ 60 sec for 3â€“5 documents)
- ğŸ§‘â€ğŸ’¼ Persona-aware & job-guided content filtering

---

## ğŸ§° Tech Stack

| Component         | Tool / Library                  |
|-------------------|----------------------------------|
| PDF Parser        | `PyMuPDF` (fitz)                 |
| Embedding Model   | `all-MiniLM-L6-v2` (80MB)        |
| NLP Libraries     | `sentence-transformers`, `transformers` |
| Language          | Python 3.10                      |
| Runtime           | CPU only                         |

---

## ğŸ“ Project Structure

```bash
project-root/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ pdfs/                 # Input folder for uploaded PDFs
â”‚   â”œâ”€â”€ outputs/              # Auto-generated input/output JSONs
â”‚       â”œâ”€â”€ input.json
â”‚       â””â”€â”€ output.json
â”‚   
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
    â””â”€â”€ json_utils.py
â”‚   
â”œâ”€â”€ create_metadata.py   # Input gathering + metadata generation
â”œâ”€â”€ extract_text.py      # PDF parsing with PyMuPDF
â”œâ”€â”€ fulfill_job.py       # Core logic: ranking + output generation
â”œâ”€â”€ rank_sections.py     # Embedding + semantic scoring
â”œâ”€â”€ run.py               # End-to-end pipeline launcher
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â””â”€â”€ approach_explanation.md
```

## âš™ï¸ Setup Instructions

Follow these steps to set up and run the project locally in an isolated environment.

---

### 1. Prerequisite: Install Docker
Ensure Docker is installed and running on your system.

- ğŸ”— [Download Docker Desktop](https://docs.docker.com/desktop/setup/install/windows-install/)
- Verify Installation:
```bash
docker --version
```

### 2. Clone the Repository

```bash
git clone https://github.com/sanchitapatel29/Codebuddies_round_1b.git
cd Codebuddies_round_1b
```

### 3. Build the Docker Image
```bash
docker build -t codebuddies2 .
```
This will take several minutes on the first build (approx 50 - 60 minutes)

### 4. Add Input PDFs

Place your .pdf files inside the following folder:
```bash
app/pdfs/
```
If it doesnâ€™t exist, create it manually.

### 5. Run the container
```bash
docker run --rm -it `
  -v "${PWD}\app\pdfs:/app/pdfs" `
  -v "${PWD}\app\outputs:/app/outputs" `
  --network none `
  codebuddies2
```

This script will:
- Prompt for persona and job-to-be-done
- Generate:
    - app/outputs/input.json
    - app/outputs/output.json



ğŸ‰ You're Ready to Go!

Your offline, CPU-friendly NLP pipeline will extract, rank, and refine the most relevant sections based on your specified persona and task.
